#!/usr/bin/env python3
import datetime
from collections import namedtuple
import json
import logging
import os

import click
import s3fs

from wildfire.goes import band, downloader, scan, utilities
from wildfire.threshold_model import model

DATETIME_FORMATS = ["%Y-%m-%dT%H:%M:%S"]
WILDFIRE_FILENAME = "wildfires_{satellite}_{region}_s{start}_e{end}_c{created}.json"

ProcessScanArgs = namedtuple(
    "ProcessScanArgs", ("s3_scan_filepaths", "local_directory", "s3")
)

logging.basicConfig(level=logging.INFO)
_logger = logging.getLogger(__name__)


@click.command()
@click.argument("satellite", type=click.Choice(["noaa-goes16", "noaa-goes17"]))
@click.argument("region", type=click.Choice(["M1", "M2", "C", "F"]))
@click.argument("start", type=click.DateTime(formats=DATETIME_FORMATS))
@click.argument("end", type=click.DateTime(formats=DATETIME_FORMATS))
@click.argument("goes_directory", type=click.Path(exists=True, file_okay=False))
@click.argument("wildfires_directory", type=click.Path(exists=True, file_okay=False))
def label_wildfires(satellite, region, start, end, goes_directory, wildfires_directory):
    """Label GOES satellite data matching parameters with wildfires.

    `bin/label_training_data noaa-goes17 M1 2019-01-01T01:00:00 2019-01-01T01:10:00 goes_data labeled_wildfires`

    SATELLITE must be in the set (noaa-goes16, noaa-goes17). e.g. noaa-goes17\n
    REGION be in the set (M1, M2, F, C). e.g. M1\n
    START must be in the following format: YYYY-MM-DDTHH:MM:SS. e.g. 2019-01-01T10:55:30\n
    END must be in the following format: YYYY-MM-DDTHH:MM:SS. e.g. 2019-01-01T10:55:30\n
    GOES_DIRECTORY is a path to a local directory at which to look for and persist
    scans. Directory must already exist. e.g. ./downloaded_data\n
    WILDFIRES_DIRECTORY is a path to a local directory at which to persist wildfires.
    Directory must already exist. e.g. ./downloaded_data\n
    """
    _logger.info(
        """Downloading available GOES satellite data fulfilling parameters:
    Satellite: %s
    Region: %s
    Start Time: %s
    End Time: %s
    Lookup Directory: %s
    Persist Directory: %s""",
        satellite,
        region,
        start,
        end,
        goes_directory,
        wildfires_directory,
    )
    s3 = s3fs.S3FileSystem(anon=True, use_ssl=False)

    _logger.info("Listing files in S3...")
    s3_filepaths = downloader.list_files(
        satellite=satellite, region=region, start_time=start, end_time=end
    )

    _logger.info("Grouping files into scans...")
    s3_scan_filepaths = utilities.group_filepaths_into_scans(filepaths=s3_filepaths)

    _logger.info(
        "Processing %d scans with %d workers...", len(s3_scan_filepaths), os.cpu_count()
    )
    wildfires = utilities.imap_function(
        function=_process_scan,
        function_args=[
            ProcessScanArgs(s3_scan, goes_directory, s3) for s3_scan in s3_scan_filepaths
        ],
    )
    wildfires = list(filter(None, wildfires))
    _logger.info("Found %d wildfires.", len(wildfires))

    if len(wildfires) > 0:
        wildfires_filepath = os.path.join(
            wildfires_directory,
            WILDFIRE_FILENAME.format(
                satellite=satellite,
                region=region,
                start=start.strfitme(DATETIME_FORMATS[0]),
                end=end.strfitme(DATETIME_FORMATS[0]),
                created=datetime.datetime.utcnow().strfitme(DATETIME_FORMATS[0]),
            ),
        )
        _logger.info("Persisting wildfires to %s", wildfires_filepath)
        with open(wildfires_filepath, "w+") as buffer:
            json.dump(dict(enumerate(wildfires)), buffer)

    _logger.info("Completed.")


def _read_scan(s3_filepath, local_directory, s3):
    local_filepath = utilities.s3_filepath_to_local(
        s3_filepath=s3_filepath, local_directory=local_directory
    )
    if not os.path.exists(local_filepath):
        _logger.info("Downloading %s...", s3_filepath)
        local_filepath = downloader.download_file(
            s3_filepath=s3_filepath, local_directory=local_directory, s3=s3
        )
    return band.read_netcdf(
        filepath=local_filepath, transform_func=band.filter_bad_pixels
    )


def _process_scan(args):
    s3_filepaths = args.s3_scan_filepaths
    local_directory = args.local_directory
    s3 = args.s3
    goes_scan = scan.GoesScan(
        bands=[
            _read_scan(s3_filepath=s3_filepath, local_directory=local_directory, s3=s3)
            for s3_filepath in s3_filepaths
        ]
    )
    if model.has_wildfire(goes_scan=goes_scan):
        return {
            "scan_time_utc": goes_scan.scan_time_utc.strftime("%Y-%m-%dT%H:%M:%S%f"),
            "region": goes_scan.region,
            "satellite": goes_scan.satellite,
        }
    return None


if __name__ == "__main__":
    label_wildfires()
